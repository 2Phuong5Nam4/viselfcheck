#!/usr/bin/env python3
"""
Practical script to run all four models from modeling_mqag.py
Configuration is automatically loaded from viselfcheck.config.settings
You can also override model paths by setting environment variables:
- MQAG_QA_GENERATOR_PATH
- MQAG_DISTRACTOR_GENERATOR_PATH  
- MQAG_QUESTION_ANSWERER_PATH
- MQAG_QUESTION_CURATOR_PATH
"""

import sys
import os
import torch
from pathlib import Path

# Add the src directory to Python path
current_dir = Path(__file__).parent
src_path = current_dir / "viselfcheck" / "src"
sys.path.insert(0, str(src_path))

try:
    from viselfcheck.modeling.modeling_mqag import (
        QAGenerator, 
        DistractorGenerator, 
        QuestionAnswerer, 
        QuestionCurator
    )
    from viselfcheck.config.settings import MQAGConfig
except ImportError as e:
    print(f"Import error: {e}")
    print("Make sure the viselfcheck package is properly installed or the path is correct.")
    sys.exit(1)

# Load configuration from settings
config = MQAGConfig()
MODEL_PATHS = {
    'qa_generator': os.getenv('MQAG_QA_GENERATOR_PATH', config.qa_generator_check_point),
    'distractor_generator': os.getenv('MQAG_DISTRACTOR_GENERATOR_PATH', config.distractor_generator_check_point),
    'question_answerer': os.getenv('MQAG_QUESTION_ANSWERER_PATH', config.answerer_check_point),
    'question_curator': os.getenv('MQAG_QUESTION_CURATOR_PATH', config.answerability),
}

# Additional configuration from settings
PIPELINE_CONFIG = {
    'num_questions_per_sent': config.num_questions_per_sent,
    'scoring_method': config.scoring_method,
    'AT': config.AT,
    'beta1': config.beta1,
    'beta2': config.beta2,
}

def print_results(contexts, questions, answers, distractors, answer_probs, quality_scores):
    """Print formatted results from all models"""
    
    print("\n" + "=" * 100)
    print("COMPLETE RESULTS FROM ALL FOUR MODELS")
    print("=" * 100)
    
    for i in range(len(contexts)):
        print(f"\n{'-' * 50} CONTEXT {i+1} {'-' * 50}")
        print(f"üìÑ CONTEXT:")
        print(f"   {contexts[i]}")
        
        print(f"\n‚ùì GENERATED QUESTION:")
        print(f"   {questions[i]}")
        
        print(f"\n‚úÖ GENERATED ANSWER:")
        print(f"   {answers[i]}")
        
        print(f"\nüéØ GENERATED DISTRACTORS:")
        for j, distractor in enumerate(distractors[i], 1):
            print(f"   {j}. {distractor}")
        
        print(f"\nüìä ANSWER PROBABILITIES:")
        options = [answers[i]] + distractors[i][:3]  # Correct answer + 3 distractors
        for j, (option, prob) in enumerate(zip(options, answer_probs[i])):
            indicator = "üéØ" if j == 0 else "‚ùå"
            print(f"   {indicator} {option}: {prob:.4f}")
        
        print(f"\n‚≠ê QUESTION QUALITY SCORE:")
        print(f"   {quality_scores[i]:.4f} (0.0 = poor, 1.0 = excellent)")

def run_complete_pipeline(contexts, model_paths, batch_size=2):
    """
    Run the complete MQAG pipeline with all four models
    
    Args:
        contexts: List of text contexts
        model_paths: Dictionary with paths to all four models
        batch_size: Batch size for processing
        
    Returns:
        Dictionary with all results
    """
    
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"üñ•Ô∏è  Using device: {device}")
    
    results = {}
    
    # Validate model paths - check if they are valid strings
    for model_name, path in model_paths.items():
        if not path or not isinstance(path, str):
            raise ValueError(f"Invalid model path for {model_name}: {path}")
    
    try:
        # Step 1: Generate questions and answers
        print("\nüîÑ Step 1: Loading QA Generator...")
        qa_generator = QAGenerator(
            checkpoint_path=model_paths['qa_generator'],
            device=device,
            max_length=512
        )
        
        print("   Generating questions and answers...")
        questions, answers = qa_generator.generate(contexts, batch_size=batch_size)
        results['questions'] = questions
        results['answers'] = answers
        print(f"   ‚úÖ Generated {len(questions)} question-answer pairs")
        
        # Step 2: Generate distractors
        print("\nüîÑ Step 2: Loading Distractor Generator...")
        distractor_generator = DistractorGenerator(
            checkpoint_path=model_paths['distractor_generator'],
            device=device,
            max_length=512,
            num_distractions=3
        )
        
        print("   Generating distractors...")
        distractors = distractor_generator.generate(contexts, questions, answers, batch_size=batch_size)
        results['distractors'] = distractors
        print(f"   ‚úÖ Generated distractors for {len(distractors)} questions")
        
        # Step 3: Evaluate question answering
        print("\nüîÑ Step 3: Loading Question Answerer...")
        question_answerer = QuestionAnswerer(
            checkpoint_path=model_paths['question_answerer'],
            device=device,
            max_length=512
        )
        
        print("   Evaluating answer probabilities...")
        options = [[answer] + distractor_list[:3] for answer, distractor_list in zip(answers, distractors)]
        answer_probs = question_answerer.predict(contexts, questions, options, batch_size=batch_size)
        results['answer_probabilities'] = answer_probs
        print(f"   ‚úÖ Computed answer probabilities for {len(answer_probs)} questions")
        
        # Step 4: Evaluate question quality
        print("\nüîÑ Step 4: Loading Question Curator...")
        question_curator = QuestionCurator(
            checkpoint_path=model_paths['question_curator'],
            device=device,
            max_length=512
        )
        
        print("   Evaluating question quality...")
        quality_scores = question_curator.predict(contexts, questions, batch_size=batch_size)
        results['quality_scores'] = quality_scores
        print(f"   ‚úÖ Computed quality scores for {len(quality_scores)} questions")
        
        results['contexts'] = contexts
        return results
        
    except Exception as e:
        print(f"‚ùå Error during pipeline execution: {e}")
        raise

def display_configuration():
    """Display the loaded configuration and sources"""
    print(f"\nüìã Loaded Model Configuration:")
    
    env_overrides = []
    for model_name, model_path in MODEL_PATHS.items():
        env_var_map = {
            'qa_generator': 'MQAG_QA_GENERATOR_PATH',
            'distractor_generator': 'MQAG_DISTRACTOR_GENERATOR_PATH', 
            'question_answerer': 'MQAG_QUESTION_ANSWERER_PATH',
            'question_curator': 'MQAG_QUESTION_CURATOR_PATH'
        }
        
        env_var = env_var_map.get(model_name)
        if env_var:
            is_override = os.getenv(env_var) is not None
            
            if is_override:
                env_overrides.append(env_var)
                print(f"   {model_name}: {model_path} ‚ö° (from {env_var})")
            else:
                print(f"   {model_name}: {model_path}")
        else:
            print(f"   {model_name}: {model_path}")
    
    print(f"\n‚öôÔ∏è  Pipeline Configuration:")
    for param_name, param_value in PIPELINE_CONFIG.items():
        print(f"   {param_name}: {param_value}")
    
    if env_overrides:
        print(f"\nüîß Environment variable overrides detected: {', '.join(env_overrides)}")

def main():
    # Sample contexts
    contexts = [
        "H√† N·ªôi, th·ªß ƒë√¥ c·ªßa Vi·ªát Nam, n·∫±m ·ªü v·ªã tr√≠ 21¬∞01‚Ä≤B 105¬∞52‚Ä≤ƒêÔªø / Ôªø21.017¬∞B 105.867¬∞ƒêÔªø / 21.017; 105.867.  Th√†nh ph·ªë n·∫±m ·ªü ph√≠a B·∫Øc Vi·ªát Nam, thu·ªôc v√πng ƒë·ªìng b·∫±ng s√¥ng H·ªìng, tr√™n l∆∞u v·ª±c s√¥ng H·ªìng v√† s√¥ng ƒêu·ªëng.  V·ªã tr√≠ ƒë·ªãa l√Ω n√†y ƒë·∫∑t H√† N·ªôi ·ªü v√πng kh√≠ h·∫≠u nhi·ªát ƒë·ªõi gi√≥ m√πa, v·ªõi m√πa h√® n√≥ng ·∫©m v√† m√πa ƒë√¥ng l·∫°nh kh√¥.  Th√†nh ph·ªë c√≥ di·ªán t√≠ch kho·∫£ng 3358,5 km¬≤, tr·∫£i d√†i tr√™n nhi·ªÅu huy·ªán, th·ªã x√£ v√† qu·∫≠n.  H√† N·ªôi n·∫±m c√°ch bi·ªÉn ƒê√¥ng kho·∫£ng 100 km v·ªÅ ph√≠a ƒê√¥ng, v√† c√≥ bi√™n gi·ªõi gi√°p v·ªõi c√°c t·ªânh Vƒ©nh Ph√∫c, B·∫Øc Ninh, H∆∞ng Y√™n, H√† Nam.  V·ªã tr√≠ trung t√¢m c·ªßa H√† N·ªôi so v·ªõi c√°c th√†nh ph·ªë l·ªõn kh√°c trong khu v·ª±c c≈©ng ƒë√≥ng vai tr√≤ quan tr·ªçng trong vi·ªác k·∫øt n·ªëi giao th√¥ng v√† kinh t·∫ø.","['H√† N·ªôi, th·ªß ƒë√¥ c·ªßa Vi·ªát Nam, n·∫±m ·ªü v·ªã tr√≠ 21¬∞01‚Ä≤B 105¬∞52‚Ä≤ƒê\ufeff / \ufeff21.017¬∞B 105.867¬∞ƒê\ufeff / 21.017; 105.867.', 'Th√†nh ph·ªë n·∫±m ·ªü ph√≠a B·∫Øc Vi·ªát Nam, thu·ªôc v√πng ƒë·ªìng b·∫±ng s√¥ng H·ªìng, tr√™n l∆∞u v·ª±c s√¥ng H·ªìng v√† s√¥ng ƒêu·ªëng.', 'V·ªã tr√≠ ƒë·ªãa l√Ω n√†y ƒë·∫∑t H√† N·ªôi ·ªü v√πng kh√≠ h·∫≠u nhi·ªát ƒë·ªõi gi√≥ m√πa, v·ªõi m√πa h√® n√≥ng ·∫©m v√† m√πa ƒë√¥ng l·∫°nh kh√¥.', 'Th√†nh ph·ªë c√≥ di·ªán t√≠ch kho·∫£ng 3358,5 km¬≤, tr·∫£i d√†i tr√™n nhi·ªÅu huy·ªán, th·ªã x√£ v√† qu·∫≠n.', 'H√† N·ªôi n·∫±m c√°ch bi·ªÉn ƒê√¥ng kho·∫£ng 100 km v·ªÅ ph√≠a ƒê√¥ng, v√† c√≥ bi√™n gi·ªõi gi√°p v·ªõi c√°c t·ªânh Vƒ©nh Ph√∫c, B·∫Øc Ninh, H∆∞ng Y√™n, H√† Nam.', 'V·ªã tr√≠ trung t√¢m c·ªßa H√† N·ªôi so v·ªõi c√°c th√†nh ph·ªë l·ªõn kh√°c trong khu v·ª±c c≈©ng ƒë√≥ng vai tr√≤ quan tr·ªçng trong vi·ªác k·∫øt n·ªëi giao th√¥ng v√† kinh t·∫ø.",
        
        "Tr·∫ßn H∆∞ng ƒê·∫°o (1228-1300), t√™n th·∫≠t l√† Tr·∫ßn Qu·ªëc Tu·∫•n, l√† m·ªôt v·ªã t∆∞·ªõng qu√¢n, nh√† ch√≠nh tr·ªã l·ªói l·∫°c c·ªßa Vi·ªát Nam th·ªùi Tr·∫ßn. √îng l√† ng∆∞·ªùi c√≥ c√¥ng lao to l·ªõn trong ba l·∫ßn kh√°ng chi·∫øn ch·ªëng qu√¢n Nguy√™n M√¥ng th·∫ø k·ª∑ XIII, ƒë∆∞·ª£c coi l√† v·ªã anh h√πng d√¢n t·ªôc, ng∆∞·ªùi anh h√πng b·∫•t t·ª≠ c·ªßa Vi·ªát Nam.  V·ªõi t√†i nƒÉng qu√¢n s·ª± xu·∫•t ch√∫ng, √¥ng ƒë√£ ba l·∫ßn ƒë√°nh b·∫°i qu√¢n Nguy√™n h√πng m·∫°nh, b·∫£o v·ªá n·ªÅn ƒë·ªôc l·∫≠p d√¢n t·ªôc.  Kh√¥ng ch·ªâ l√† m·ªôt danh t∆∞·ªõng, Tr·∫ßn H∆∞ng ƒê·∫°o c√≤n l√† m·ªôt nh√† ch√≠nh tr·ªã, chi·∫øn l∆∞·ª£c gia t√†i ba, v·ªõi nh·ªØng chi·∫øn l∆∞·ª£c, k·∫ø s√°ch ƒë·ªôc ƒë√°o, s√°ng t·∫°o, ƒë∆∞·ª£c th·ªÉ hi·ªán r√µ n√©t trong ""Binh th∆∞ y·∫øu l∆∞·ª£c"" - t√°c ph·∫©m qu√¢n s·ª± n·ªïi ti·∫øng c·ªßa √¥ng.  S·ª± nghi·ªáp hi·ªÉn h√°ch c·ªßa √¥ng ƒë√£ ƒë·ªÉ l·∫°i d·∫•u ·∫•n s√¢u ƒë·∫≠m trong l·ªãch s·ª≠ Vi·ªát Nam, tr·ªü th√†nh bi·ªÉu t∆∞·ª£ng c·ªßa l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn qu·∫≠t c∆∞·ªùng v√† tr√≠ tu·ªá s√°ng su·ªët c·ªßa d√¢n t·ªôc.","['Tr·∫ßn H∆∞ng ƒê·∫°o (1228-1300), t√™n th·∫≠t l√† Tr·∫ßn Qu·ªëc Tu·∫•n, l√† m·ªôt v·ªã t∆∞·ªõng qu√¢n, nh√† ch√≠nh tr·ªã l·ªói l·∫°c c·ªßa Vi·ªát Nam th·ªùi Tr·∫ßn.', '√îng l√† ng∆∞·ªùi c√≥ c√¥ng lao to l·ªõn trong ba l·∫ßn kh√°ng chi·∫øn ch·ªëng qu√¢n Nguy√™n M√¥ng th·∫ø k·ª∑ XIII, ƒë∆∞·ª£c coi l√† v·ªã anh h√πng d√¢n t·ªôc, ng∆∞·ªùi anh h√πng b·∫•t t·ª≠ c·ªßa Vi·ªát Nam.', 'V·ªõi t√†i nƒÉng qu√¢n s·ª± xu·∫•t ch√∫ng, √¥ng ƒë√£ ba l·∫ßn ƒë√°nh b·∫°i qu√¢n Nguy√™n h√πng m·∫°nh, b·∫£o v·ªá n·ªÅn ƒë·ªôc l·∫≠p d√¢n t·ªôc.', 'Kh√¥ng ch·ªâ l√† m·ªôt danh t∆∞·ªõng, Tr·∫ßn H∆∞ng ƒê·∫°o c√≤n l√† m·ªôt nh√† ch√≠nh tr·ªã, chi·∫øn l∆∞·ª£c gia t√†i ba, v·ªõi nh·ªØng chi·∫øn l∆∞·ª£c, k·∫ø s√°ch ƒë·ªôc ƒë√°o, s√°ng t·∫°o, ƒë∆∞·ª£c th·ªÉ hi·ªán r√µ n√©t trong ""Binh th∆∞ y·∫øu l∆∞·ª£c"" - t√°c ph·∫©m qu√¢n s·ª± n·ªïi ti·∫øng c·ªßa √¥ng.', 'S·ª± nghi·ªáp hi·ªÉn h√°ch c·ªßa √¥ng ƒë√£ ƒë·ªÉ l·∫°i d·∫•u ·∫•n s√¢u ƒë·∫≠m trong l·ªãch s·ª≠ Vi·ªát Nam, tr·ªü th√†nh bi·ªÉu t∆∞·ª£ng c·ªßa l√≤ng y√™u n∆∞·ªõc, tinh th·∫ßn qu·∫≠t c∆∞·ªùng v√† tr√≠ tu·ªá s√°ng su·ªët c·ªßa d√¢n t·ªôc."
    ]
    
    print("üöÄ MQAG Pipeline Test Script")
    print("=" * 50)
    print(f"üìù Processing {len(contexts)} contexts")
    
    # Display loaded configuration
    display_configuration()
    
    try:
        # Run the complete pipeline
        results = run_complete_pipeline(contexts, MODEL_PATHS, batch_size=2)
        
        # Print results
        print_results(
            results['contexts'],
            results['questions'],
            results['answers'],
            results['distractors'],
            results['answer_probabilities'],
            results['quality_scores']
        )
        
        print(f"\nüéâ Pipeline completed successfully!")
        print(f"üìä Summary: Processed {len(contexts)} contexts and generated {len(results['questions'])} questions")
        
    except Exception as e:
        print(f"\n‚ùå Pipeline failed: {e}")
        print("Please check your model paths and ensure all models are accessible.")

if __name__ == "__main__":
    main()
